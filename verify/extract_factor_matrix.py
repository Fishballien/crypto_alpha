# -*- coding: utf-8 -*-
"""
Created on Thu Dec 26 15:53:38 2024

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ðŸŒŸ â­ âœ¨ ðŸŒ  ðŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… âŽ
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: âž” âžœ âž™ âž¤ âž¥ â†© â†ª
emoji: ðŸ”” â³ â° ðŸ”’ ðŸ”“ ðŸ›‘ ðŸš« â— â“ âŒ â­• ðŸš€ ðŸ”¥ ðŸ’§ ðŸ’¡ ðŸŽµ ðŸŽ¶ ðŸ§­ ðŸ“… ðŸ¤” ðŸ§® ðŸ”¢ ðŸ“Š ðŸ“ˆ ðŸ“‰ ðŸ§  ðŸ“

"""
# %% imports
import sys
from pathlib import Path
import pandas as pd
from functools import partial
import numpy as np
from datetime import datetime
import pickle


# %% add sys path
file_path = Path(__file__).resolve()
file_dir = file_path.parents[0]
project_dir = file_path.parents[1]
sys.path.append(str(project_dir))


# %%
from utils.dirutils import load_path_config
from utils.datautils import load_all_factors, get_one_factor
from data_processing.feature_engineering import normalization


# %%
def generate_half_hour_timestamps_pandas(date_str):
    """
    ç”ŸæˆæŒ‡å®šæ—¥æœŸå†…æ¯åŠå°æ—¶ä¸€ä¸ªçš„æ—¶é—´æˆ³åˆ—è¡¨ã€‚

    å‚æ•°:
    - date_str (str): æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º 'YYYYMMDD'ã€‚

    è¿”å›ž:
    - List[str]: æ ¼å¼ä¸º 'YYYY-MM-DD HH:MM:SS' çš„æ—¶é—´æˆ³åˆ—è¡¨ã€‚
    """
    # å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸º pandas Timestamp
    start = pd.to_datetime(date_str, format='%Y%m%d')
    # ç”ŸæˆåŠå°æ—¶é—´éš”çš„æ—¶é—´èŒƒå›´ï¼Œè¦†ç›–æ•´å¤©ï¼ˆ48ä¸ªæ—¶é—´ç‚¹ï¼‰
    timestamps = pd.date_range(start=start, periods=48, freq='30min')
    # å°† Timestamp è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
    return timestamps.strftime('%Y-%m-%d %H:%M:%S').tolist()


def norm_factor(factor, to_mask, normalization_func):
    factor_mask = factor.isna() | to_mask
    factor_masked = factor.mask(factor_mask)
    factor = normalization_func(factor_masked)
    factor = factor.mask(factor_mask)
    return factor


def convert_timestamp_format(timestamp_str):
    """
    å°†æ—¶é—´æˆ³ä»Ž '%Y-%m-%d %H:%M:%S' æ ¼å¼è½¬æ¢ä¸º '%Y%m%d%H%M%S' æ ¼å¼ã€‚

    å‚æ•°:
    - timestamp_str (str): åŽŸå§‹æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º '%Y-%m-%d %H:%M:%S'ã€‚

    è¿”å›ž:
    - str: è½¬æ¢åŽçš„æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º '%Y%m%d%H%M%S'ã€‚
    """
    try:
        # è§£æžåŽŸå§‹æ—¶é—´æˆ³å­—ç¬¦ä¸²
        dt = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
        # æ ¼å¼åŒ–ä¸ºæ–°æ ¼å¼
        new_format = dt.strftime('%Y%m%d%H%M%S')
        return new_format
    except ValueError as e:
        print(f"æ—¶é—´æ ¼å¼é”™è¯¯: {e}")
        return None


# %%
cluster_name = 'agg_250127_cgy_zxt_double3m'
period = '230201_250201'
date = '20250220'
twap_name = 'twd30_sp30'
cluster_path = f'/mnt/Data/xintang/crypto/multi_factor/factor_test_by_alpha/results/cluster/{cluster_name}/cluster_info_{period}.csv'
sp = 30
outlier = 30
start_date = '20250219'
end_date = '20250224'
res_dir = Path('/mnt/Data/xintang/crypto/multi_factor/factor_test_by_alpha/results/verify') / cluster_name
res_dir.mkdir(parents=True, exist_ok=True)


# %%
file_path = Path(__file__).resolve()
project_dir = file_path.parents[1]
path_config = load_path_config(project_dir)
twap_dir = Path(path_config['twap_price'])
data_dir = Path(path_config['processed_data'])


# %%
twap_path = twap_dir / f'{twap_name}.parquet'
twap_price = pd.read_parquet(twap_path)
twap_price = twap_price[(twap_price.index >= start_date) & (twap_price.index < end_date)]
to_mask = twap_price.isna()


# %%
cluster_info = pd.read_csv(cluster_path)
cluster_info = cluster_info[cluster_info['factor'].apply(lambda x: 'P0.4' in x)].reset_index(drop=True)
# cluster_info.loc[cluster_info['process_name'] == 'LOB_2024-12-13_valid0.2_R2', 'process_name'] = 'LOB_2024-12-26_f64_R2'
# cluster_info.loc[cluster_info['process_name'] == 'LOB_2024-12-13_valid0.2_R1', 'process_name'] = 'LOB_2024-12-26_f64_R1'


# %%
normalization_func = partial(normalization, outlier_n=outlier)


# %%
get_one_factor_func = partial(get_one_factor, sp=sp, 
                              date_start=start_date, date_end=end_date,
                              ref_order_col=twap_price.columns, ref_index=twap_price.index)
factor_dict = load_all_factors(cluster_info, get_one_factor_func, data_dir, 100)
factor_norm_dict = {fac_idx: norm_factor(factor, to_mask, normalization_func) for fac_idx, factor in factor_dict.items()}


# %%
group = {}
group_norm = {}

for gid, group_info in cluster_info.groupby('group'):
    len_of_group = len(group_info)
    group_factor = None
    for id_, index in enumerate(group_info.index):
        process_name, factor_name, direction = group_info.loc[index, ['process_name', 'factor', 'direction']]
        factor = factor_dict[index]
        if not process_name.startswith('gp'):
            factor_mask = factor.isna() | to_mask
            factor_masked = factor.mask(factor_mask)
            factor = normalization_func(factor_masked)
            if factor is None:
                len_of_group -= 1
                print(process_name, factor_name)
                continue
            factor = factor.mask(factor_mask) # TODO: æ”¹ä¸ºç”¨å‚æ•°è®¾ç½®mask
        factor = factor * direction
        if group_factor is None:
            group_factor = factor
        else:
            group_factor += factor
    group_factor = group_factor / len_of_group
    group[gid] = group_factor
    group_factor = normalization_func(group_factor)
    group_norm[gid] = group_factor
    

# %%
timestamps = generate_half_hour_timestamps_pandas(date)

for ts in timestamps:

    factor_df = pd.DataFrame(np.nan, index=twap_price.columns, columns=np.arange(len(cluster_info)))
    factor_norm_df = pd.DataFrame(np.nan, index=twap_price.columns, columns=np.arange(len(cluster_info)))
    group_df = pd.DataFrame(np.nan, index=twap_price.columns, columns=np.arange(len(cluster_info['group'].unique())))
    group_norm_df = pd.DataFrame(np.nan, index=twap_price.columns, columns=np.arange(len(cluster_info['group'].unique())))
    
    
    for fac_idx, factor in factor_dict.items():
        factor_df.loc[:, fac_idx] = factor.loc[ts, :]
    for fac_idx, factor_norm in factor_norm_dict.items():
        factor_norm_df.loc[:, fac_idx] = factor_norm.loc[ts, :]
    # for gid, group_factor in group.items():
    #     group_df.loc[:, gid] = group_factor.loc[ts, :]
    # for gid, group_norm_factor in group_norm.items():
    #     group_norm_df.loc[:, gid] = group_norm_factor.loc[ts, :]
        
    res = {
           'factor_org': factor_df,
           'factor_norm': factor_norm_df,
           # 'group_org': group_df,
           # 'group_norm': group_norm_df,
           }
    with open(res_dir / f"{convert_timestamp_format(ts)}.pkl", 'wb') as f:
        pickle.dump(res, f)